
![SSC-logo-300x171](https://github.com/franciellevargas/HateBR/blob/5611312b1573cb1e5689fae64ab4ede88502ed78/.github/Logo-DCCUFMG.jpg)
![SSC-logo-300x171](https://github.com/franciellevargas/HateBR/blob/7e5fe34063f89296b17f8c255b89360dfef75761/.github/icmc.png)     ![SSC-logo-300x171](https://github.com/franciellevargas/HateBR/blob/1c2ecbc54df5719102d068370b3eca9dacea8334/.github/locus_media.png)


<h2 align="center"> A Sentence-Level Annotated Dataset to Predict Factually and Media Bias </h2>  


</br>
<p align="justify">Automated news credibility and fact-checking at scale require accurate prediction of news factuality and media bias. Here, we introduce a large sentence-level dataset, titled FactNews, composed of 6,191 sentences expertly annotated according to factuality and media bias definitions proposed by AllSides. We use FactNews to assess the overall reliability of news sources by formulating two text classification problems for predicting sentence-level factuality of news reporting and bias of media outlets. Our experiments demonstrate that biased sentences present a higher number of words compared to factual sentences, besides having a predominance of emotions. Hence, the fine-grained analysis of subjectivity and impartiality of news articles showed promising results for predicting the reliability of the entire media outlet. Finally, due to the severity of fake news and political polarization in Brazil, and the lack of research for Portuguese, both dataset and baseline were proposed for Brazilian Portuguese. The following table describes in detail the labels, documents, and stories for FactNews: </p>
</br>

</br>
<div align="center">

| Factual| Quotes | Biased | Total sentences | Total news stories | Total news documents |
| :---   | :---:  |   ---: |            ---: |               ---: |                  ---: |
| 4,242  | 1,391  | 558    | 6,161           | 100                | 300                   |

</div>
</br>

</br>
<div align="center">

| Media 1        | Media 2  | Media 3 | 
| :---           | :---:    |   ---: |  
| Folha de São Paulo   | Estadão  | O Globo    | 
</div>
</br>

</br>
<div align="center">

| Sentence-Level Media Bias Prediction   | Sentenve-Level Factuality Prediction  |
| :---                                   | :---:    |   
| 67% (F1-Score) by BERT Fine-Tuning    | 0.88% (F1-Score) by BERT-Fine Tuning  | 
</div>
</br>
<h2 align="left"> CITING </h2>

<p align="justify">
Vargas, F., Jaidka, K., Pardo, T.A.S., Benevenuto, F. (2023). Predicting Sentence-Level Factuality of News and Bias of Media Outlets. Proceedings of the Recent Advances in Natural Language Processing, pp.1-10. Varna, Bulgaria. Association for Computational Linguistics (ACL). 

</p>


<br>

<h2 align="left"> FUNDING </h2>

![SSC-logo-300x171](https://github.com/franciellevargas/franciellevargas.github.io/blob/9f2aba738836e85dbedbe969010ed8593d1c0d69/img/sinch-logo.png)
![SSC-logo-300x171](https://github.com/franciellevargas/HateBR/blob/e5ccb9cd6b43c26edacb2c4abd32fd75f8a574a2/.github/logo_novo_english.gif)
![SSC-logo-300x171](https://github.com/franciellevargas/HateBR/blob/1c6044026c8617de939f562c83e1e45c19ca8c89/.github/cnpq.png)

</br>


